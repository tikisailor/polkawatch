# Deployment Tutorial

A ```docker-compose``` for production is provided in this folder with the actual services required for deployment.

Polkawatch can simply be deployed by running:

```bash
$ docker-compose up 
```

# About data Volumes

Polkawatch does not require the Data Volumes to be backed up, as the data is generated from the Substrate blockchain,
however, generating the data, in particular the archive phase, is very time-consuming. In that sense it might be worth
storing a backup of the postgress ``pgdata`` volume. At present time the backup requires 100Mb per 1M blocks when 
compressed.

# Daily Data Pack Generation

On top of the docker-compose above a batch process for daily Data Pack generation is required.

The IPFS data pack is generated by a gulpfile (or wrapping script) and can be triggered daily from a gitlab pipeline for 
convenience. A sample ```.gitlabci.yml``` for this purpose is provided. It delivers a ```.car``` archive ready for 
publishing. 

An additional step should be provided to actually upload the car file on IPFS infrastructure and update entrypoint records
such as DNS records pointing to the Data Pack's CID.

# When to generate the Data Pack?

The ideal hour for pipeline execution can be decided using Kibaba as follows:

- Create a scripted file that extracts the hour from the ```Date``` field of the Reward event.
- Create an histogram of Rewards by creation hour.

At the time of writing most rewards are generated between 16-19h UTC. This depends on how Validators/Nominators are 
triggering the rewards claiming process. The daily 2-pass indexing can be set to
run at 19h and the Data Pack publishing pipeline at 19.30 or 20h. This can be reviewed on regular basis.